<!DOCTYPE html>

<html>

<head>
  <meta charset="htf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
  <!-- Bootstrap -->
  <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href="css/theme.css" rel="stylesheet">
  <link href="assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">
  <script src="assets/js/ie-emulation-modes-warning.js"></script>

  <title> Ke Sun's homepage</title>
</head>

<body>
  <script src="js/jquery.js"></script>
  <script src="js/bootstrap.min.js"></script>

  <div class="container">

  <nav class="navbar navbar-inverse">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Ke Sun</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="index.html#">Home</a></li>
            <!-- <li><a href="research.html#">Research</a></li> -->
            <li><a href="publication.html#">Publication</a></li>
            <li><a href="index.html#Honor">Honor & Award</a></li>
            <li><a href="index.html#Service">Service</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
  </nav>

    <div class="col-md-8">
      <div class="col-md-8">
        <h2>Ke Sun</h2>
        <p><i class="fa fa-graduation-cap"></i>  Ph.D. candidate, <a href="https://cse.ucsd.edu/">Department of Computer Science and Engineering</a>, University of California, San Diego</p>
        <p><i class="fa fa-graduation-cap"></i>  Incoming Tenure-track Assistant Professor, <a href="https://cse.engin.umich.edu/">Computer Science and Engineering</a>, <a href="https://cse.engin.umich.edu/">EECS Department</a>, University of Michigan, Ann Arbor</p>
        <!-- <p><i class="fa fa-home"></i>  La Jolla, CA, 92093 </p> -->
        <p><i class="fa fa-envelope-o"></i>  <a href="mailto:kesun@ucsd.edu">kesun@ucsd.edu</a>
        <i class="fa fa-envelope-o"></i>  <a href="mailto:kesuniot@umich.edu">kesuniot@umich.edu</a> </p>
        <!-- <i class="fa fa-envelope"></i>  <a href="mailto:kesun@smail.nju.edu.cn">kesun@smail.nju.edu.cn</a> -->
        <p> <i class="fa fa-envelope"></i>  <a href="mailto:samsonsunke@gmail.com">samsonsunke@gmail.com</a></p>
        <p><i class="fa fa-github"></i> <a href="https://github.com/Samsonsjarkal/">  Samsonsjarkal</a>
        <i class="fa fa-google"></i> <a href="https://scholar.google.com/citations?user=YZWCK4gAAAAJ&hl=en">  Google Scholar</a>
        <i class="fa fa-file"></i> <a href="files/kesun_cv.pdf">  Resume</a></p>
      </div>
      <div class="col-md-4">
        <img src="img/photo_KeSun_UMich.jpg"  alt="Personal photo"  height="200"/>
      </div>
      <div class="col-md-12 page-header" id="biography">
        <h3> <i class="fa fa-id-card-o"></i> Biography</h3>
        <p>
          <b><span class="pub-strong">I will be joining the Computer Science and Engineering (CSE) in the Electrical Engineering and Computer Science (EECS) department at University of Michigan, Ann Arbor as an Assistant Professor in Jan 2025! 
          I am actively recruiting undergraduate and graduate researchers. If you're interested, please check <a href="https://amilabumich.notion.site/Get-Involved-89ad599393044e2dbbb37877f18511b1">Openings in AmI Lab @ UMich CSE.</a></span></b>
        </p>
        <p>
        I am a final-year Ph.D. candidate in Computer Science and Engineering at the University of California, San Diego, advised by <a href="http://xyzhang.ucsd.edu"> Prof. Xinyu Zhang</a>. 
        </p>
        <p>
        Committed to the vision of "ambient intelligence", my research delves into the creation of end-to-end <b>intelligent, cost-effective, deployable, and human-centric sensing systems</b> for Mobile, Wearable and IoT ecosystems.
        Specifically, we will i). Enable novel applications; ii). Advance computational sensing techniques; iii). Address system bottlenecks; and iv). Harness innovative sensing modalities for MWIoT ecosystems.
        </p>
        <p>
          My work has won the <b>ACM IMWUT (UbiComp) Distinguished Paper Award</b> and <b>ACM SenSys Best Poster Runner-up</b>. The tangible impact of my research is also manifested in real-world applications, with successful deployments on widely-recognized IoT devices such as Amazon Echo and Google Home. 
          Additionaly, I'm privileged to have been chosen as the <b>Google Ph.D. Fellowship</b> (the sole recipient in Mobile Computing area among candidates in North America and Europe).
        </p>
        In the mobile and IoT realm, my work intersects various disciplines, driving innovation across different applications
        <br><br>
        <ul>
          <li><b>HCI for Mobile, AV/VR and IoT:</b></li>
          Single-modal: <a href="#scalar">SCALAR</a> (TMC'23), <a href="#dsw">DSW</a> (INFOCOM'20), <a href="#vskin">VSKIN</a> (MobiCom'18), <a href="#llap">LLAP</a> (MobiCom'16) &emsp;
          Multi-modal: <a href="#ultrase">UltraSE</a> (MobiCom'21), <a href="#exgsense">ExGSense</a> (IPSN'21), <a href="#dolphin">Dolphin</a> (MobiSys'18)
          <li><b>Mobile and IoT Cybersecurity:</b></li>
          <a href="#magmaw">Magmaw</a> (NDSS'25), <a href="#stealthyimu">StealthyIMU</a> (NDSS'23), <a href="#micshield">MicShield</a> (SenSys'20), <a href="#spidermon">SpiderMon</a> (INFOCOM'20), <a href="#unlock">Unlock With Your Heart</a> (UbiComp'18)
          <li><b>Mobile and IoT Health and Environmental Sensing:</b></li>
          <a href="#egoadl">EgoADL</a> (UbiComp'24), <a href="#loear">LoEar</a> (UbiComp'22), <a href="#vector">VECTOR</a> (UbiComp'22)
          <li><b>Mobile and IoT Robotics using Wireless Signals:</b></li>
          <a href="#rfcanvas">RFCanvas</a> (SenSys'24), <a href="#milliego">milliEgo</a> (SenSys'20)
        </ul>        
        <!-- <p>I received my M.Eng. degree in Computer Science at <a href="https://www.nju.edu.cn/EN/"> Nanjing University, China </a> in 2019, and B.Eng. degree in Computer Science at <a href="http://iao.nuaa.edu.cn"> Nanjing University of Aeronautics and Astronautics, China </a> in 2016.
        </p> -->
      </div>
      <!-- <div class="col-md-12 page-header" id="education">
        <h3> <i class="fa fa-graduation-cap"></i> Education</h3>
        <div class="col-md-8">
        <li><b>Ph.D. of Computer Science</b>   2019~present
        <p>University of California, San Diego, Supervisor: <a href="http://xyzhang.ucsd.edu"> Prof. Xinyu Zhang </a>
        </li>
        </div>
        <div class="col-md-4">
        <img src="img/ucsd.jpg"  alt="ucsd.jpg"  width="50"/>
        </div>
        <br><br><br>
        <div class="col-md-8">
        <li><b>Master of Computer Science and Technology</b>   2016~2019
        <p>Nanjing University, Nanjing, Supervisor: <a href="https://cs.nju.edu.cn/ww/"> Prof. Wei Wang </a></p>
        </li>
        </div>
        <div class="col-md-4">
        <img src="img/nju.png"  alt="nju.png"  width="40"/>
        </div>
        <br><br><br>
        <div class="col-md-8">
        <li><b>Bachelor of Computer Science and Technology</b>   2012~2016
        <p>Nanjing University of Aeronautics and Astronautics, Nanjing</p>
        </li>
        </div>
        <div class="col-md-4">
        <img src="img/nuaa.png"  alt="nuaa.png"  width="40"/>
        </div>
      </div> -->
    </div>
      <div class="col-md-4 page-header" id="news">
        <h3><i class="fa fa-newspaper-o"></i>   News</h3>
          <ul>
            <li> <h5>Jan 2024</h5>
                EgoADL has been accepted by <b>IMWUT (UbiComp) 2024</b>. Stay tuned for our new wearable techniques for daily life logging, along with our new dataset and platform. </a>
            <li> <h5>Oct 2023</h5>
              I won the <a href="https://today.ucsd.edu/story/computer-science-students-garner-2023-google-phd-fellowships"><b>Google Ph.D. Fellowship 2023 in Mobile Computing</b></a>. Thank you Google! </a>
            <li> <h5>Oct 2023</h5>
              VECTOR (Ultrasound-based temperature-field monitoring) won the <b>Distinguished Paper Award</b> in UbiComp 2023. Congratulations to all of the cooperators! </a>
            <li> <h5>Oct 2023</h5>
              Working in <b>Amazon Lab126</b> as an Applied Scientist Intern three years in a row. I am honored that many of my projects have been the blueprint of Amazon Echo devices. </a>
            <li> <h5>Dec 2022</h5>
              StealthyIMU has been accepted by <b>NDSS 2023</b>. Please check our <a href="https://github.com/Samsonsjarkal/StealthyIMU">opensource dataset and code.</a>
            <!-- <li> <h5>Sep 2022</h5>
              Another fantastic internship in Amazon Lab126. Stay tune for our latest technology. -->
            <li> <h5>July 2022</h5>
              VECTOR (Ultrasound-based temperature-field monitoring) and LoEar (Long-range vital sign monitoring using ultrasound) have been accepted by <b>IMWUT (UbiComp) 2022</b>.
            <!-- <li> <h5>Sep 2021</h5>
              A wonderful internship as an Applied Scientist Intern in Amazon Lab 126 this summer. -->
            <!-- <li> <h5>June 2021</h5>
              I will join Amazon 126 Lab as an Applied Scientist Intern this summer. -->
            <li> <h5>Jan 2021</h5>
              UltraSE has been accepted by <b>ACM MobiCom 2021</b>.
            <!-- <li> <h5>Jan 2021</h5>
              ExGSense has been accepted by <b>ACM/IEEE IPSN 2021</b>. -->
            <!-- <li> <h5>Sept 2020</h5>
              Two papers, "MicShield" and "milliEgo" have been accepted by <b>ACM SenSys 2020</b>.</li> -->
            <!-- <li> <h5>Dec 2019</h5>
              Two papers, "SpiderMon" and "Dynamic Speed Warping" have been accepted by <b>IEEE INFOCOM 2020</b>.</li> -->
            <!-- <li> <h5>Apr 2019</h5>
              Begin to pursue my Ph.D. at <b>UCSD</b> with <a href="http://xyzhang.ucsd.edu/index.html"> Prof. Xinyu Zhang</a> in 19'Fall.</li> -->
            <!-- <li> <h5>Mar 2019</h5>
              Our work 'CapTag' has been accepted by <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2019-north-america">2019 Qualcomm innovation fellowship finalist</a>! -->
            <!-- <li> <h5>Jul 2018</h5>
              Our paper "Unlock With Your Heart" has been accepted by <b>ACM IMWUT (UbiComp 2018)</b>.</li> -->
            <!--<li> <h5>May 2018</h5>
              Our paper "VSkin" has been conditionally accepted by <b>ACM MobiCom 2018</b>.</li> -->
            <!-- <li> <h5>May 2018</h5>
              Our paper "Charging Task Scheduling for Directional Wireless Charger Networks" has been accepted by <b>ACM ICPP 2018</b>.</li> -->
          	<!-- <li> <h5>Feb 2018</h5>
              Our paper "WiTrace" has been accepted by <b>IEEE SECON 2018</b>.</li> -->
            <!-- <li> <h5>Feb 2018</h5>
              Our paper "Depth Aware Finger Tapping on Virtual Displays" has been accepted by <b>ACM MobiSys 2018</b>.</li> -->
            <!--<img src="img/ARtype.jpg"  alt="ARtype.jpg"  width="250"/>-->
            <!-- <li><h5>May 2017</h5>
              Our project "Ultrasound based sensing applications for mobile devices" achieves <b>First Prize</b> in 2017 China National College Competition on Internet of Things.</li> -->
            <!-- <li><h5>May 2017</h5>
              We have released the iOS ultrasound gesture system. You can download the source code from <a href="https://github.com/Samsonsjarkal/LLAP/blob/master/README.md"> Github</a>.</li> -->
            <!-- <li><h5>Nov 2016</h5>
              Our ultrasound work has been reported by <b>MIT Technology Review</b>: <a href="https://www.technologyreview.com/s/602834/this-app-lets-you-control-your-phone-using-sonar/"> This App Lets You Control Your Phone Using Sonar"</a>.</li> -->
            <!-- <img src="img/llapfly.gif"  alt="llapfly"  width="250"/> -->
            <!-- <li><h5>Oct 2016</h5>
              Our paper and demo "Device-free gesture tracking using acoustic signals" has been accepted by <b>ACM MobiCom 2016</b>. Check our <a href="https://www.youtube.com/watch?v=gs8wMrOSY80"> Demo Video.</a></li> -->
            <!-- <li> <h5> Jun 2016</h5>
              I receive my B.Sc. degree of Computer Science from NUAA and achieve <b>Undergraduate Achievement Award</b> (22 NUAA undergraduates annually).</li> -->
            <!-- <li> <h5> Dec 2015</h5>
              I receive the NUAA(Nanjing University of Aeronautics and Astronautics) University <b>President Award</b> (10 NUAA undergraduates annually)!</li> -->
              <!-- <img src="img/president.JPG"  alt="president.jpg"  width="250"/> -->
            <!-- <li> <h5> Oct 2015</h5>
              I receive the CCF(China Computer Federation) <b>Outstanding Undergraduate Award</b> (100 undergraduates all over China).</li> -->
            <!-- <li> <h5> Oct 2015</h5>
              Our team achieves <b>Gold Medal</b> in the 40th ACM International Collegiate Programming Contest (ACM/ICPC) Asia Regional Contest (School Rank 9 and Team Rank 13 from 217 teams).</li> -->
              <!-- <img src="img/icpc.JPG"  alt="icpc.jpg"  width="250"/> -->
          </ul>
      </div>

      <div class="col-md-12 page-header" id="Honor">
        <h3> <i class="fa fa-thumbs-up"></i> Selected Honor and Awards</h3>
        <li>2023 Google Ph.D. Fellowship in Mobile Computing <b>Sole recipient in Mobile Computing area among candidates in North America and Europe</b></li>
        <li>2023 UbiComp Distinguished Paper Award <b>8 out of 210 accepted papers.</b></li>
        <li>2021 ACM MobiCom Student Travel Grants </li>
        <li>2020 ACM SenSys Best Poster Award Runner-ups <b>3 out of 84 accepted posters.</b></li>
        <li>2020 Jiangsu Province Computer Society Outstanding Dissertation Award  <b>Sole recipient.</b></li>
        <li>2019 Nanjing University CS Distinguished Master Thesis Award </li>
        <li>2019 Nanjing University Distinguished Graduate Student </li>
        <li>2018 ACM MobiSys Student Travel Grants </li>
        <li>2017 China National College Competition on Internet of Things, <b>Finals First Prize</b></li>
        <p>    Project: Ultrasound based sensing applications for mobile devices</p>
        <li>2015 ACM-ICPC Asia Regional Contest(Chang Chun Site), <b>Gold Medal</b></li>
        <p>    School Rank 9 and Team Rank 13 from 217 teams</p>
        <!-- <li>2016 NUAA(Nanjing University of Aeronautics and Astronautics) <b>Undergraduate Achievement Award</b> <p>22 NUAA undergraduates annually</p></li> -->
        <li>2015 CCF(China Computer Federation) Outstanding Undergraduate Award 
        <p>Top 100 undergraduates in China annually</p></li>
        <!-- <li>2015 NUAA(Nanjing University of Aeronautics and Astronautics) <b>University President Award</b> <p>10 NUAA undergraduates annually</p></li> -->
<!--         <li>2015 China National Aero-Technology Import & Export Scholarship</li> -->
        <!-- <li>2014 China National Scholarship</li> -->
        <!-- <li>2013 Fei Xiaotong Scholarship</li> -->
      </div>
      <div class="col-md-12 page-header" id="publication">
        <h3> <i class="fa fa-bookmark"></i> Selected Publication (<a href="publication.html#">Full List</a>)</h3> 
        <div class="col-md-8">
          <p style="font-size:16px" class="paper-wireless paper-mobile" id="magmaw">
                  <a href="" target="#magmaw">Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems (To Appear)
                  </a><br/>
                  <span class="pub-authors">Jung-Woo Chang, <b>Ke Sun</b>, Nasimeh Heydaribeni, Seira Hidano, Xinyu Zhang, Farinaz Koushanfa</span><br/>
                   <span class="pub-strong">NDSS 2025</span>, Feb 2025.
                  </p>
                  We propose Magmaw, a novel attack methodology targeting deep neural network (DNN)-based joint source-channel coding (JSCC) wireless communication systems. Magmaw is capable of generating universal adversarial perturbations for any multimodal signal transmitted over a wireless channel.
          </div>
          <div class="col-md-4">
            <img src="img/magmaw.png"  alt="magmaw"  width="250"/>
          </div>
          <div class="col-md-12">
            <br><br>
          </div>
          <div class="col-md-8">
            <p style="font-size:16px" class="paper-wireless paper-mobile" id="rfcanvas">
                    <a href="" target="#rfcanvas">RFCanvas: Modeling RF Channel by Fusing Visual Priors and Few-shot RF Measurements (To Appear)
                    </a><br/>
                    <span class="pub-authors">Xingyu Chen, Zihao Feng, <b>Ke Sun</b>, Kun Qian, Xinyu Zhang</span><br/>
                     <span class="pub-strong">SenSys 2024</span>, Nov 2024.
                    </p>
                    We propose RFCanvas, which fuses visual priors and RF measurements to achieve high accuracy for realistic scenes and be responsive to environmental changes.
            </div>
            <div class="col-md-4">
              <img src="img/rf_canvas.png"  alt="rfcanvas"  width="250"/>
            </div>
            <div class="col-md-12">
              <br><br>
            </div>
        <div class="col-md-8">
          <p style="font-size:16px" class="paper-wireless paper-mobile" id="egoadl">
                  <a href="" target="#egoadl">Multimodal Daily-life Logging in Free-living Environments Using Non-Visual Egocentric Sensors on a Smartphone
                  </a><br/>
                  <span class="pub-authors"><b>Ke Sun</b>, Chunyu Xia, Xinyu Zhang, Hao Chen, Charlie Zhang</span><br/>
                   <span class="pub-strong">ACM IMWUT (UbiComp) 2024</span>, March 2024.
                  </p>
                  We propose EgoADL, the first egocentric ADL sensing system that uses an in-pocket smartphone as a multi-modal sensor hub to capture body motion, interaction with the physical environment and daily objects using non-visual sensors (audio, wireless sensing, and motion sensors).
          </div>
          <div class="col-md-4">
            <img src="img/egoadl.png"  alt="egoadl"  width="250"/>
          </div>
          <div class="col-md-12">
            <br><br>
          </div>
        <div class="col-md-8">
          <p style="font-size:16px" class="paper-wireless paper-mobile" id="stealthyimu">
                  <a href="files/ndss23_StealthyIMU.pdf" target="stealthyimu">StealthyIMU: Extracting Permission-protected Private Information from Smartphone Voice Assistant using Zero-Permission Sensors</a><br/>
                  <span class="pub-authors"><b>Ke Sun</b>, Chunyu Xia, Songlin Xu, Xinyu Zhang</span><br/>
                   <span class="pub-strong">NDSS 2023</span>, Feb 2023. (Acceptance ratio: 58/398=14.6%)
                   <a href="files/ndss23_StealthyIMU.pptx" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
                   <a href="https://github.com/Samsonsjarkal/StealthyIMU"><i class="fa fa-github fa-fw w3-text-indigo"></i></a>
                  </p>
                  We propose StealthyIMU, a new threat that uses side channel to steal permission-protected private information from the voice-user interface.
          </div>
          <div class="col-md-4">
            <img src="img/stealthyimu.jpg"  alt="stealthyimu"  width="250"/>
          </div>
          <div class="col-md-12">
            <br><br>
          </div>
          <div class="col-md-8">
            <p style="font-size:16px" class="paper-wireless paper-mobile" id="scalar">
                    <a href="" target="scalar">SCALAR: Self-Calibrated Acoustic Ranging for Distributed Mobile Devices</a><br/>
                    <span class="pub-authors">Lei Wang, Haoran Wan, Ting Zhao, <b>Ke Sun</b>, Shuyu Shi, Haipeng Dai, Guihai Chen, Haodong Liu, Wei Wang</span><br/>
                     <span class="pub-strong">IEEE TMC 2023</span>
                    </p>
                    We propose SCALAR, a self-calibrated acoustic ranging system that achieves sub-millimeter ranging accuracy on distributed commercial devices.
            </div>
            <div class="col-md-4">
              <img src="img/scalar.jpg"  alt="scalar"  width="250"/>
            </div>
            <div class="col-md-12">
              <br><br>
            </div>
        <div class="col-md-8">
          <p style="font-size:16px" class="paper-wireless paper-mobile" id="vector">
                  <a href="files/ubicomp22vector.pdf" target="vector">VECTOR: Velocity Based Temperature-field Monitoring with Distributed Acoustic Devices</a><br/>
                  <span class="pub-authors">Haoran Wan, Lei Wang, Ting Zhao, <b>Ke Sun</b>, Shuyu Shi, Haipeng Dai, Guihai Chen, Haodong Liu, Wei Wang</span><br/>
                   <span class="pub-strong">ACM IMWUT (UbiComp) 2022</span>, Sep 2022. 
                  </p>
                  We introduce VECTOR, a temperature-field monitoring system that achieves high temperature sensing accuracy and fast response time using commercial sound playing/recording devices.
          </div>
          <div class="col-md-4">
            <img src="img/room_scenarios_cropped.jpg"  alt="vector"  width="250"/>
          </div>
          <div class="col-md-12">
            <br><br>
          </div>

        <div class="col-md-8">
          <p style="font-size:16px" class="paper-wireless paper-mobile" id="loear">
                  <a href="files/ubicomp22loear.pdf" target="loear">LoEar: Push the Range Limit of Acoustic Sensing for Vital Sign Monitoring</a><br/>
                  <span class="pub-authors">Lei Wang, Wei Li, <b>Ke Sun</b>, Fusang Zhang, Tao Gu, Chenren Xu, Daqing Zhang</span><br/>
                   <span class="pub-strong">ACM IMWUT (UbiComp) 2022</span>, Sep 2022. 
                  </p>
                   We propose LoEar, which is a novel acoustic sensing system using only a single microphone and speaker to detect vital signs (respiration and heartbeat) with a significantly increased sensing range (> 6 meter).
          </div>
          <div class="col-md-4">
            <img src="img/loear.jpeg"  alt="loear"  width="250"/>
          </div>
          <div class="col-md-12">
            <br><br>
          </div>

        <div class="col-md-8">
          <p style="font-size:16px" class="paper-wireless paper-mobile" id="ultrase">
                  <a href="files/mobicom21_UltraSE.pdf" target="ultrase">UltraSE: Single-Channel Speech Enhancement Using Ultrasound</a><br/>
                  <span class="pub-authors"><b>Ke Sun</b>, Xinyu Zhang</span><br/>
                   <span class="pub-strong">ACM MobiCom 2021</span>, Oct 2021. (Acceptance ratio: 60/299=20.1%)
                   <a href="files/mobicom21_ultrase.pptx" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
                   <a href="https://www.youtube.com/watch?v=WBFkKBgMWrg"><i class="fa fa-film fa-fw"></i></a> </p>
                   We propose UltraSE, which uses ultrasound sensing as a complementary modality to separate the desired speaker’s voice from interferences and noise.
          </div>
          <div class="col-md-4">
            <img src="img/ultrase.jpg"  alt="ultrase"  width="250"/>
          </div>
          <div class="col-md-12">
            <br><br>
          </div>

        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="exgsense">
                <a href="files/IPSN21_ExGSense.pdf" target="exgsense">ExGSense: Toward Facial Gesture Sensing and Reconstruction with a Sparse Near-Eye Sensor Array </a><br/>
                <span class="pub-authors">Chen Chen, <b>Ke Sun</b>, Xinyu Zhang</span><br/>
                 <span class="pub-strong">ACM/IEEE IPSN 2021</span>, May 2021. (Acceptance ratio: 26/105=24.8%)</p> 
                 ExGSense propose to sense whole facial gestures by using a sparse set of biopotential transducers. We propose a dual-branch multiview representation learning
                 model, which can explicitly exploit the sensor diversities across time-frequency-spatial domains.
        </div>
        <div class="col-md-4">
          <img src="img/exgsense.gif"  alt="exgsense"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>

        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="micshield">
                <a href="files/sensys20_micShield.pdf" target="micshield">"Alexa, Stop Spying on Me": Speech Privacy Protection Against Voice Assistants</a><br/>
                <span class="pub-authors"><b>Ke Sun</b>, Chen Chen, Xinyu Zhang</span><br/>
                 <span class="pub-strong">ACM SenSys 2020</span>, Nov 2020. (Acceptance ratio: 43/213=20.2%)
                 <a href="files/MicShield_SenSys20_slide.pptx" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
                 <a href="https://www.youtube.com/watch?v=eBsrUGH1MVQ&list=PL6jLuiS6wP5aNxDPxOsXfd3Rrv0l_26rn&index=6"><i class="fa fa-film fa-fw"></i></a> </p>
                 MicShield is a companion device with voice assistant to enable the selective jamming mechanism which, for the first time, prevents VAs from recording private speech without affecting the voice assistants’ normal functionalities.
        </div>
        <div class="col-md-4">
          <img src="img/micshield.jpg"  alt="micshield"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="milliego">
                <a href="files/sensys20_milliego.pdf" target="milliego">milliEgo: Single-chip mmWave Radar Aided Egomotion Estimation via Deep Sensor Fusion</a><br/>
                <span class="pub-authors">Chris Xiaoxuan Lu, Muhamad Risqi U. Saputra, Peijun Zhao, Yasin Almalioglu, Pedro P. B. de Gusmao, Changhao Chen, <b>Ke Sun</b>, Niki Trigoni, Andrew Markham</span><br/>
                 <span class="pub-strong">ACM SenSys 2020</span>, Nov 2020. (Acceptance ratio: 43/213=20.2%)
                 <a href="https://www.youtube.com/watch?v=5LG-PbrUSO8&feature=youtu.be"><i class="fa fa-film fa-fw"></i></a>
                </p>
                 milliEgo is a novel deep-learning approach that demonstrates the feasibility of mmWave odometry and provides a fusion framework to develop a robust mmWaveInertial Odometry.
        </div>
        <div class="col-md-4">
          <img src="img/milliego.jpg"  alt="milliego"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="dsw">
                <a href="files/infocom20_dsw.pdf" target="_blank">Dynamic Speed Warping: Similarity-Based One-shot Learning for Device-free Gesture Signals</a><br/>
                <span class="pub-authors">Xun Wang, <b>Ke Sun</b>, Ting Zhao, Wei Wang, Qing Gu</span><br/>
                 <span class="pub-strong">IEEE INFOCOM 2020</span>, April 2020. (Acceptance ratio: 267/1397=19.1%)</p> 
                 We propose a Dynamic Speed Warping (DSW) algorithm to enable one-shot learning for device-free gesture signals performed by different users.
                 DSW provides a robust similarity measure between gesture samples and can work for both one-shot learning in supervised gesture recognition and unsupervised learning tasks.
        </div>
        <div class="col-md-4">
          <img src="img/dsw.jpg"  alt="dsw"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="spidermon">
                <a href="files/infocom20_SpiderMon.pdf" target="_blank">SpiderMon: Towards Using Cell Towers as Illuminating Sources for Keystroke Monitoring</a><br/>
                <span class="pub-authors">Kang Ling, Yuntang Liu, <b>Ke Sun</b>, Wei Wang, Lei Xie, Qing Gu</span><br/>
                 <span class="pub-strong">IEEE INFOCOM 2020</span>, April 2020. (Acceptance ratio: 267/1397=19.1%)</p> 
                SpiderMon is a system that performs longrange keystroke monitoring using the signal transmitted by commercial 4G/5G cellular base stations. We show
                that SpiderMon can detect keystroke movements at a distance of 15 meters or even behind the wall.
        </div>
        <div class="col-md-4">
          <img src="img/SpinderMon.gif"  alt="SpiderMon"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="vskin">
                <a href="files/mobicom18_vskin.pdf" target="_blank">VSkin: Sensing Touch Gestures on Surfaces of Mobile Devices Using Acoustic Signals</a><br/>
                <span class="pub-authors"><b>Ke Sun</b>, Ting Zhao, Wei Wang, Lei Xie</span><br/>
                 <span class="pub-strong">ACM MobiCom 2018</span>, October 2018 (Acceptance ratio: 42/187=22.5%).
                 <a href="files/mobicom18_vskin_slides.pptx" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
                <a href="https://www.youtube.com/watch?v=POujv7hm3Z4"><i class="fa fa-film fa-fw"></i></a> </p>
                VSkin is a system that supports fine-grained touch gesture sensing on the back of mobile devices based on acoustic signals.
                VSkin utilizes both the structure-borne sounds, i.e., sounds propagating through the structure of the device, and the air-borne sounds, 
                i.e., sounds propagating through the air, to sense touch gestures.
        </div>
        <div class="col-md-4">
          <img src="img/vskin.gif"  alt="vskin"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="unlock">
                <a href="files/ubicomp18Heartbeat.pdf" target="_blank">Unlock With Your Heart: Heartbeat-based Authentication on Commercial Mobile Phones</a><br/>
                <span class="pub-authors">Lei Wang, Kang Huang, <b>Ke Sun</b>, Wei Wang, Chen Tian, Lei Xie, Qing Gu</span><br/>
                 <span class="pub-strong">ACM IMWUT (UbiComp) 2018</span>, October 2018. <a href="files/ubicomp18_heartbeat_slides.pptx" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
                 <a href="https://www.youtube.com/watch?v=9aviE6DOHJc"><i class="fa fa-film fa-fw"></i></a> </p>
                 ''Unlock with your heart'' uses the built-in accelerometer to capture the heartbeat signals on commercial mobile phones.
                 The user only needs to press the phone on his/her chest, and the system can identify the user within a few heartbeats. 
        </div>
        <div class="col-md-4">
          <img src="img/Heartbeat.gif"  alt="heartbeat"  width="250"/>
        </div>
        <div class="col-md-12">
          <br><br>
        </div>
        <!-- <div class="col-md-10">
        <p class="paper-wireless paper-mobile">
        		<a href="files/ICPP18_CHATS.pdf" target="_blank">
                Charging Task Scheduling for Directional Wireless Charger Networks</a><br/>
                <span class="pub-authors">Haipeng Dai, <b>Ke Sun</b>, Alex X. Liu, Lijun Zhang, Jiaqi Zheng and Guihai Chen</span><br/>
                 <span class="pub-strong">ACM ICPP 2018</span>, August 2018. <br/>
                 <span> Extented: <a href="" target="_blank">Charging Task Scheduling for Directional Wireless Charger Networks</a></span><br/>
                 <span class="pub-authors">Haipeng Dai, <b>Ke Sun</b>, Alex X. Liu, Lijun Zhang, etc.</span><br/>
                 <span class="pub-strong">IEEE Transactions on Mobile Computing</span>, 2020.
               </p>
        </div> -->
        <!-- <div class="col-md-2">
        </div> -->
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="dolphin">
                <a href="files/mobisys18_ARTyping.pdf" target="_blank">Depth Aware Finger Tapping on Virtual Displays</a><br/>
                <span class="pub-authors"><b>Ke Sun</b>, Wei Wang, Alex X. Liu, Haipeng Dai</span><br/>
                 <span class="pub-strong">ACM MobiSys 2018</span>, June 2018. (Acceptance ratio: 37/138=26.8%)
                 <a href="files/mobisys18_ARTyping_slides.pdf" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a> </p>
                 Dolphin is a fine-grained depthaware tapping scheme that can provide high accuracy tapping detection. It uses light-weight ultrasound based sensing, 
                 along with one COTS mono-camera, to enable 3D tracking of fingers.
        </div>
        <div class="col-md-4">
          <img src="img/ARtype.jpg"  alt="Dolphin"  width="250"/>
        </div>
        <!-- <div class="col-md-10">
        <p class="paper-wireless paper-mobile">
                <a href="files/secon18_witrace.pdf" target="_blank">WiTrace: Centimeter-Level Passive Gesture Tracking Using WiFi Signals</a><br/>
                <span class="pub-authors">Lei Wang, <b>Ke Sun</b>, Haipeng Dai, Alex X. Liu, Xiaoyu Wang</span><br/>
                 <span class="pub-strong">IEEE SECON 2018</span>, June 2018. <br/>
                 <span> Extented: <a href="" target="_blank">WiTrace: Centimeter-Level Passive Gesture Tracking Using OFDM Signals</a></span><br/>
                 <span class="pub-authors">Lei Wang, <b>Ke Sun</b>, Haipeng Dai, Wei Wang, Kang Huang, etc.</span><br/>
                 <span class="pub-strong">IEEE Transactions on Mobile Computing</span>, 2019. </p>
        </div>
        <div class="col-md-2">
          <a href="files/secon18_witrace_slides.pdf" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
        </div> -->
        <div class="col-md-12">
          <br><br>
        </div>
        <div class="col-md-8">
        <p style="font-size:16px" class="paper-wireless paper-mobile" id="llap">
                <a href="files/mobicom16_ultrasound.pdf" target="_blank">Device-free Gesture Tracking using Acoustic Signals</a><br/>
                <span class="pub-authors">Wei Wang, Alex X. Liu, <b>Ke Sun</b></span><br/>
                <span class="pub-strong">ACM MobiCom 2016</span>, October 2016. (Acceptance ratio: 31/226=13.7%)
                <a href="files/mobicom16_ultrasound_slides.pdf" target="_blank"><i class="fa fa fa-file-powerpoint-o fa-fw"></i></a>
                <a href="https://www.youtube.com/watch?v=gs8wMrOSY80"><i class="fa fa-film fa-fw"></i></a>
                <a href="https://github.com/Samsonsjarkal/LLAP/blob/master/README.md"><i class="fa fa-github fa-fw w3-text-indigo"></i></a></p>
                LLAP is an ultrasound-based device-free gesture tracking scheme that can be deployed on existing mobile devices as software, without any hardware modification. We use speakers and
                microphones that already exist on most mobile devices to perform device-free tracking of a hand/finger. <br>
                <b><span class="pub-strong"> MIT Technology Review</span></b>: <a href="https://www.technologyreview.com/s/602834/this-app-lets-you-control-your-phone-using-sonar/"> This App Lets You Control Your Phone Using Sonar</a>
        </div>
        <div class="col-md-4">
          <img src="img/llapfly.gif"  alt="LLAP"  width="250"/>
        </div>
      </div>

      <!-- <div class="col-md-12 page-header" id="Award">
        <h3> <i class="fa fa-thumbs-up"></i> Award</h3>
        <li>2017 China National College Competition on Internet of Things, October 2017, <b>Finals First Prize</b></li>
        <p>    Project: Ultrasound based sensing applications for mobile devices</p>
        <li>2015 ACM-ICPC Asia Regional Contest(Chang Chun Site), October 2015, <b>Gold Medal</b></li>
        <p>    School Rank 9 and Team Rank 13 from 217 teams</p>
        <li>2014 ACM-ICPC China Shanghai Metropolitan Programming Contest, May 2015, <b>Silver Medal</b></li>
        <li>2013 ACM-ICPC China TongHua Invitational Programming Contest, May 2013, <b>Silver Medal</b></li>
        <p>    School Rank 14 and Team Rank 18 from 137 teams</p> -->
<!--         <li>The Fifth China National Professional Software Engineering "Lan Qiao Cup" Design Contest(Java Goup) <p>June 2014, <b>Finals Second Prize</b>.</p></li>
        <li>The Fourth China National Professional Software Engineering "Lan Qiao Cup" Design Contest(C/C++ Goup) <p>July 2013, <b>Finals Second Prize</b>.</p></li> -->
      <!-- </div> -->
      
      <div class="col-md-12 page-header" id="Service">
        <h3> <i class="fa fa-thumbs-up"></i> Service</h3>
        Reviewer
        <li> 2024 IEEE ICASSP, ACM IMWUT (UbiComp)</li>
        <li> 2023 IEEE ICASSP, ACM TMC, ACM TOSN</li>
        <li> 2022 IEEE ICASSP, ACM IMWUT (UbiComp), IEEE TMC, ACM SenSys Shadow PC </li>
        <li> 2021 ACM TOSN, IEEE TMC, ACM MobileHCI </li>
        <li> 2020 IEEE TMC, ACM IMWUT (UbiComp)</li>
        Program Committee Member:
        <li> 2022 ACM SenSys Shadow PC</li>
        Organizer and Chair:
        <li> 2023 ICLR Machine Learning for IoT Workshop Co-organizer and Session Chair</li>
      </div>

  </div>


  <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="assets/js/ie10-viewport-bug-workaround.js"></script>
</body>

</html>